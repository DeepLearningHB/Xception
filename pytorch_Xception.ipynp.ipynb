{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xception(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Xception, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, stride=2,padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 0)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 1, 2, 0) # first 1x1 convolution\n",
    "        self.sConv1 = SeparableConv(64, 128, 3, 1, 1)\n",
    "        self.sConv2 = SeparableConv(128, 128, 3, 1, 1)\n",
    "        self.pool1 = nn.MaxPool2d(3, 2, padding=1)\n",
    "        # if cat.operation()=='concat' -> (256, ) \n",
    "        # elif cat.operation()=='add' -> (128, )\n",
    "        self.m_flow = MiddleBlock()\n",
    "        self.sConv3 = SeparableConv(128, 256, 3, 1, 1)\n",
    "        self.sConv4 = SeparableConv(256, 256, 3, 1, 1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, 1, 2, 0)\n",
    "        self.sConv5 = SeparableConv(256, 728, 3, 1, 1)\n",
    "        self.sConv6 = SeparableConv(728, 728, 3, 1, 1)\n",
    "        self.conv6 = nn.Conv2d(256, 728, 1, 2, 0)\n",
    "        self.conv7 = nn.Conv2d(728, 1024, 1, 2, 0)\n",
    "        self.sConv7 = SeparableConv(728, 728, 3, 1, 1)\n",
    "        self.sConv8 = SeparableConv(728, 1024, 3, 1, 1)\n",
    "        self.sConv9 = SeparableConv(1024, 1536, 3, 1, 1)\n",
    "        self.sConv10 = SeparableConv(1536, 2048, 3, 1, 1)\n",
    "        self.linear = nn.Linear(2048, 1000)\n",
    "       # self.\n",
    "    def forward(self, input):\n",
    "        net = self.conv1(input) #Entry Flow with out BN\n",
    "        net = self.conv2(F.relu(net))\n",
    "        net_1 = self.conv3(F.relu(net))\n",
    "        net = self.sConv1(F.relu(net))\n",
    "        net = self.sConv2(F.relu(net))\n",
    "        net = self.pool1(net)\n",
    "        #net_2 = torch.cat([net, net_1]) # or + ?\n",
    "        net_2 = net + net_1\n",
    "        net = self.sConv3(F.relu(net_2))\n",
    "        net = self.sConv4(F.relu(net))\n",
    "        net = self.pool1(net)\n",
    "        net_3 = self.conv5(net_2)\n",
    "        net = net + net_3\n",
    "        net = self.sConv5(F.relu(net))\n",
    "        net = self.sConv6(F.relu(net))\n",
    "        net = self.pool1(net)\n",
    "        \n",
    "        net_4 = self.conv6(net_3)\n",
    "        net = net + net_4\n",
    "        \n",
    "        ## Middel Flow \n",
    "        for i in range(8):\n",
    "            net = self.m_flow(F.relu(net))\n",
    "        \n",
    "        to_sum = self.conv7(net)\n",
    "        net = self.sConv7(F.relu(net))\n",
    "        net = self.sConv8(F.relu(net))\n",
    "        net = self.pool1(net)\n",
    "        net = net + to_sum\n",
    "        \n",
    "        net = self.sConv9(net)\n",
    "        net = F.relu(self.sConv10(F.relu(net)))\n",
    "        \n",
    "        net = torch.mean(net, axis=[2, 3]) ## Global Average Pooling\n",
    "        net = self.linear(net)\n",
    "        net = F.softmax(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MiddleBlock, self).__init__()\n",
    "        devide = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.sConv = [SeparableConv(728, 728, 3, 1, 1).to(device) for i in range(3)]\n",
    "        print(self.sConv[0])\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        for i in range(3):\n",
    "            x = self.sConv[i](F.relu(x))\n",
    "        return input+x\n",
    "\n",
    "        \n",
    "\n",
    "class SeparableConv(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n",
    "        super(SeparableConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels, bias=bias)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, 1, bias=bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
  
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path='./'):\n",
    "    import os\n",
    "    import cv2\n",
    "    images = []\n",
    "    labels = []\n",
    "    folder_path = os.path.join(path, \"sub_path\")\n",
    "    folder_list = os.listdir(folder_path)\n",
    "    \n",
    "    for folder in folder_list:\n",
    "        file_name = os.path.join(folder_path, folder)\n",
    "        file_list = os.listdir(file_name)\n",
    "        count = 0\n",
    "        for folder in folder_list:\n",
    "            if file[-3:] != 'jpg':\n",
    "                continue\n",
    "            image = cv2.imread(os.path.join(file_name, file))\n",
    "            if image.shape != (299, 299, 3):\n",
    "                image = cv2.resize(image, (299, 299, 3))\n",
    "            label = int(folder) # Folder name : 0, 1, 2, ....\n",
    "            images.append(np.array(image))\n",
    "            labels.append(label)\n",
    "    \n",
    "    images = np.array(images).reshape(-1, 3, 299, 299)\n",
    "    labels = np.array(labels)\n",
    "    X = np.random.permutation(len(labels))\n",
    "    \n",
    "    return images[X], labels[X]\n",
    "            # You can give label as your format\n",
    "\n",
    "def calculate_accuracy(logits, labels):\n",
    "    _, predicted = torch.max(logits.data, 1)\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item() / len(labels)\n",
    "    return correct\n",
    "\n",
    "def poly_lr_scheduler(optimizer, init_lr, iter, lr_decay_iter=1,\n",
    "                      max_iter=100, power=0.9):\n",
    "    if iter % lr_decay_iter or iter > max_iter:\n",
    "        return optimizer\n",
    "\n",
    "    lr = init_lr*(1 - iter/max_iter)**power\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_size = 0\n",
    "test_size = 0\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, is_train=True):\n",
    "        global train_size\n",
    "        sub_path = \"/train\" if is_train else \"/test\"\n",
    "        self.data_x, self.data_y = read_dataset(os.path.join(\"your_path\", sub_path))\n",
    "        if is_train: train_size = len(self.data_y)\n",
    "        else: test_size = len(self.data_y)\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = None, None\n",
    "        if torch.cuda.is_available():\n",
    "            x = torch.cuda.FloatTensor(self.data_x[idx])\n",
    "            y = torch.cuda.FloatTensor(self.data_y[idx])\n",
    "        else:\n",
    "            x = torch.FloatTensor(self.data_x[idx])\n",
    "            y = torch.FloatTensor(self.data_y[idx])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    path = ''\n",
    "    epoch = 10000\n",
    "    momentum = 0.9\n",
    "    learning_rate = 0.045\n",
    "    rate_decay = 0.94\n",
    "    input_size = (3, 299, 299)\n",
    "    train_data = MyDataset()\n",
    "    test_data = MyDataset(False)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "    net = Xception().to(device)\n",
    "    \n",
    "    for ep in range(epoch):\n",
    "        avg_loss = 0\n",
    "        avg_acc = 0\n",
    "        avg_test_loss = 0\n",
    "        avg_test_acc = 0\n",
    "        fy_list = []\n",
    "        optimizer = poly_lr_scheduler(optimizer, learning_rate, ep, 2, epoch, rate_decay)\n",
    "        total_batch = int(len(train_loader) / batch_size)\n",
    "        net.train()\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batchv_x, batchv_y = Variable(batch_x.to(device)), Variable(batch_y.to(device))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_hat = net(batchv_x)\n",
    "            loss = criterion(y_hat, batch_y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss / (train_size + 1)\n",
    "            avg_acc += cal_top1_accuray(y_hat, batch_y) / (train_size + 1)\n",
    "    \n",
    "        net.eval()\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batchv_x, batchv_y = Variable(batch_x.to(device)), Variable(batch_y.to(device))\n",
    "            y_hat = net\n",
    "            y_hat = net(batchv_x)\n",
    "            loss = criterion(y_hat, batch_y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_test_loss += loss / (test_size + 1)\n",
    "            avg_test_acc += cal_top1_accuray(y_hat, batch_y) / (test_size + 1)\n",
    "        \n",
    "        if i % 5 == 4:\n",
    "            print(\"Epoch : %d || Training Cost: %.4f Training Accuracy: %.3f Test Cost: %.4f Test Accuracy: %.3f\" % (epoch+1, avg_loss, avg_acc, avg_test_loss, avg_test_acc))\n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
